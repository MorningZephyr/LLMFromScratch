{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Finding all unique characters in alphabetical order\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from chars to int, and vice versa\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# encoder and decoder functions\n",
    "encode = lambda s: [stoi[ch] for ch in s ]              # returns a list of encoded chars\n",
    "decode = lambda l: ''.join([itos[i] for i in l])        # returns the string\n",
    "\n",
    "print(encode(\"Hello, World!\"))\n",
    "print(decode(encode(\"Hello, World!\")))                  # decode(encode(s)) will return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# Using torch.Tensor to store entire text dataset (encoded)\n",
    "import torch \n",
    "\n",
    "# dtype is long because it's int64, rather than the default float32\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- storing in torch.Tensor allows a wide range of tools that comes with pytorch\n",
    "- we make the dtye=torch.long because it's int64 rather than the default float32. Since the encoder only has integer, there's no need to waste extra space for decimal precision\n",
    "\n",
    "Why do we encode the input?\n",
    "- Since computers can really only understand numbers, we have to numberfy the inputs into numbers so that they can be interpreted by the computer\n",
    "- We set words/characters to numbers so that the number will the representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up the data into training set and validation sets\n",
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]           # Used for training\n",
    "val_data = data[n:]             # Used to test how good the model is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- When we create a model, we want it to also solve problems outside of its training dataset. If a model is only good at doing what it's trained on, then it can't be generalized, which is useless\n",
    "- That is why we leave 10% of the data for validation purposes, to see how the model performs when it encounters something outside of its training set, or in other words, to see to what extent is the model overfitting\n",
    "- Overfitting is bad, because even if the model can predict the training set to a high degree, it'll not translate well to data that it has never seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given tensor([18]), my target is 47\n",
      "Given tensor([18, 47]), my target is 56\n",
      "Given tensor([18, 47, 56]), my target is 57\n",
      "Given tensor([18, 47, 56, 57]), my target is 58\n",
      "Given tensor([18, 47, 56, 57, 58]), my target is 1\n",
      "Given tensor([18, 47, 56, 57, 58,  1]), my target is 15\n",
      "Given tensor([18, 47, 56, 57, 58,  1, 15]), my target is 47\n",
      "Given tensor([18, 47, 56, 57, 58,  1, 15, 47]), my target is 58\n"
     ]
    }
   ],
   "source": [
    "# Selecting blocks \n",
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+ 1]\n",
    "for t in range(block_size):\n",
    "    print(f\"Given {x[:t+1]}, my target is {y[t]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- We pick a small block size, or context length to train data because loading all the dataset at once is impractical, such as limited memory\n",
    "- We select random chunks of the dataset and then train them. Those chunks have a max size\n",
    "\n",
    "Numbers of training data in a block:\n",
    "- When selecting a chunk/block from the dataset, there's actually mulitple training data packed into. See the above code\n",
    "- In a way, this is a bayesian framework of conditional probability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "\n",
      "targets: torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----------\n",
      "Given tensor([24]), my target is 43\n",
      "Given tensor([24, 43]), my target is 58\n",
      "Given tensor([24, 43, 58]), my target is 5\n",
      "Given tensor([24, 43, 58,  5]), my target is 57\n",
      "Given tensor([24, 43, 58,  5, 57]), my target is 1\n",
      "Given tensor([24, 43, 58,  5, 57,  1]), my target is 46\n",
      "Given tensor([24, 43, 58,  5, 57,  1, 46]), my target is 43\n",
      "Given tensor([24, 43, 58,  5, 57,  1, 46, 43]), my target is 39\n",
      "Given tensor([44]), my target is 53\n",
      "Given tensor([44, 53]), my target is 56\n",
      "Given tensor([44, 53, 56]), my target is 1\n",
      "Given tensor([44, 53, 56,  1]), my target is 58\n",
      "Given tensor([44, 53, 56,  1, 58]), my target is 46\n",
      "Given tensor([44, 53, 56,  1, 58, 46]), my target is 39\n",
      "Given tensor([44, 53, 56,  1, 58, 46, 39]), my target is 58\n",
      "Given tensor([44, 53, 56,  1, 58, 46, 39, 58]), my target is 1\n",
      "Given tensor([52]), my target is 58\n",
      "Given tensor([52, 58]), my target is 1\n",
      "Given tensor([52, 58,  1]), my target is 58\n",
      "Given tensor([52, 58,  1, 58]), my target is 46\n",
      "Given tensor([52, 58,  1, 58, 46]), my target is 39\n",
      "Given tensor([52, 58,  1, 58, 46, 39]), my target is 58\n",
      "Given tensor([52, 58,  1, 58, 46, 39, 58]), my target is 1\n",
      "Given tensor([52, 58,  1, 58, 46, 39, 58,  1]), my target is 46\n",
      "Given tensor([25]), my target is 17\n",
      "Given tensor([25, 17]), my target is 27\n",
      "Given tensor([25, 17, 27]), my target is 10\n",
      "Given tensor([25, 17, 27, 10]), my target is 0\n",
      "Given tensor([25, 17, 27, 10,  0]), my target is 21\n",
      "Given tensor([25, 17, 27, 10,  0, 21]), my target is 1\n",
      "Given tensor([25, 17, 27, 10,  0, 21,  1]), my target is 54\n",
      "Given tensor([25, 17, 27, 10,  0, 21,  1, 54]), my target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4          # How many independent chunks should we process in parallel\n",
    "block_size = 8          # Maximum context length of per chunk\n",
    "\n",
    "def get_batch(split: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"The function samples a batch of data and its respective targets(y) and returns both as 2-D torch.Tensor\"\"\"\n",
    "\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    # We're just implementing the ideas from above cell\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])                   # x values to predict the next token\n",
    "    y = torch.stack([data[i+1: i + block_size+1] for i in ix])              # y values, the target\n",
    "\n",
    "    return x,y\n",
    " \n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "print('inputs:',xb.shape)\n",
    "print(xb)\n",
    "print()\n",
    "print('targets:', yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# Our training set, comprised of input and target\n",
    "for i in range(batch_size):             # iterating each of the batch           , batch dimension\n",
    "    for j in range(block_size):         # iterating each of the training data   , time dimension\n",
    "        print(f\"Given {xb[i][:j+1]}, my target is {yb[i][j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborations:\n",
    "\n",
    "`ix = torch.randint(len(data) - block_size, (batch_size,))`\n",
    "- Here we are generating `batch_size` amount of random integers to serve as the starting index for getting chunks, where these integers are in [0, `len(data)-block_size`)\n",
    "- The range is so that we don't go oob when we try to get `block_size` amount of data from a starting index\n",
    "- The random indices will be stored in a 1D tensor, as denoted by `(batch_size,)`\n",
    "- The tuple notation signifys that it's a 1D tensor, and if we have something else like `(2,3)`, then that'll be a 2D tensor with dimensions 2X3, meaning 2 rows, each having length 3\n",
    "- If we were to write `(batch_size)` without the ',', then it'll be a scalar tensor, which doesn't make sense if I want to sample random integers and storing those collections in a container\n",
    "\n",
    "---\n",
    "`torch.stack`\n",
    "- A torch stack is when you stack a bunch tensors of SAME dimension n, and it'll become a new tensor with dimension n+1\n",
    "- For example, if I have `tensor(1)`, `tensor(2)`, `tensor(3)`, all 0D, and I stack them via torch.stack, then the resulting tensor will be a 1D vector tensor that looks like `tensor([1,2,3])`\n",
    "- If I have `tensor([1,2,3])` and `tensor([4,5,6])`, then stack will result in a 2X3 matrix\n",
    "- When it comes to training data, we stack those 1D vectors so that each vectors will be trained simultaneously via the parallel processing nature of GPU\n",
    "\n",
    "ex. Training in parallel\n",
    "\n",
    "|   <------ <1,2,3>         my independent vector1\n",
    "\n",
    "|   <------ <4,5,6>         my independent vector2\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "`x = torch.stack([data[i:i + block_size] for i in ix])` \n",
    "- For each of the random indices `i`, we sample a chunk [`i` to `index + block_size`)\n",
    "- ix is a 1D tensor, so the variable `i` will be each of the 0D/scalar tensor contained within it. A scalar tensor, `tensor(k)`, is not the same as the number `k`, so we can't use scalar tensor to index a list. We would have to use `tensor.item()` to retrieve the number and then use it to index. However, since the 'list' we're trying to index is another tensor, pytorch takes care of the conversions!\n",
    "- After we have the multiple sample chunks, we stack them into a `batch_size`X`block_size` tensor, so a 2D matrix for parallel processing\n",
    "\n",
    "`y = torch.stack([data[i+1: i + block_size+1] for i in ix])`\n",
    "- Same idea from above, except that the `y` will be the target of `x` when it comes to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding vectors\n",
    "\n",
    "Inputs are embedded into vectors to carry semantic meaning and attributes of a word. The reason why those inputs are not represented by a number, such as in hashing, is because a single number is too simple and can't express the multi-layered depth of a word. \n",
    "\n",
    "For example: `{1 : 'cat', 2 : 'dog', 3 : 'apple'}`\n",
    "\n",
    "- The model will intrepet `cat` and `dog` as similar due to their numeric proximity, which is true intuitively, since both are animals\n",
    "- However, since `dog` and `apple` have the close proximity, the ai would interpret them as being similar, which is not the case!\n",
    "- Embedding a word via vector gives more depth to it, allowing proper semantic relationship and meaning to puncture through"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
