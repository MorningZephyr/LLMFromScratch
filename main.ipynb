{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-03-03 10:29:12--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: 'input.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 3.43M 0s\n",
      "    50K .......... .......... .......... .......... ..........  9% 4.38M 0s\n",
      "   100K .......... .......... .......... .......... .......... 13% 4.58M 0s\n",
      "   150K .......... .......... .......... .......... .......... 18% 35.6M 0s\n",
      "   200K .......... .......... .......... .......... .......... 22% 11.1M 0s\n",
      "   250K .......... .......... .......... .......... .......... 27% 10.1M 0s\n",
      "   300K .......... .......... .......... .......... .......... 32% 10.9M 0s\n",
      "   350K .......... .......... .......... .......... .......... 36% 6.96M 0s\n",
      "   400K .......... .......... .......... .......... .......... 41% 21.5M 0s\n",
      "   450K .......... .......... .......... .......... .......... 45% 5.34M 0s\n",
      "   500K .......... .......... .......... .......... .......... 50% 29.3M 0s\n",
      "   550K .......... .......... .......... .......... .......... 55% 35.1M 0s\n",
      "   600K .......... .......... .......... .......... .......... 59% 5.15M 0s\n",
      "   650K .......... .......... .......... .......... .......... 64% 1.19M 0s\n",
      "   700K .......... .......... .......... .......... .......... 68%  148M 0s\n",
      "   750K .......... .......... .......... .......... .......... 73% 78.4M 0s\n",
      "   800K .......... .......... .......... .......... .......... 78%  124M 0s\n",
      "   850K .......... .......... .......... .......... .......... 82%  134M 0s\n",
      "   900K .......... .......... .......... .......... .......... 87% 2.05M 0s\n",
      "   950K .......... .......... .......... .......... .......... 91% 5.83M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 96% 7.11M 0s\n",
      "  1050K .......... .......... .......... .........            100% 8.93M=0.2s\n",
      "\n",
      "2025-03-03 10:29:13 (6.33 MB/s) - 'input.txt' saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading the data\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Finding all unique characters in alphabetical order\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from chars to int, and vice versa\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# encoder and decoder functions\n",
    "encode = lambda s: [stoi[ch] for ch in s ]              # returns a list of encoded chars\n",
    "decode = lambda l: ''.join([itos[i] for i in l])        # returns the string\n",
    "\n",
    "print(encode(\"Hello, World!\"))\n",
    "print(decode(encode(\"Hello, World!\")))                  # decode(encode(s)) will return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# Using torch.Tensor to store entire text dataset (encoded)\n",
    "import torch  # type: ignore\n",
    "\n",
    "# dtype is long because it's int64, rather than the default float32\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- storing in torch.Tensor allows a wide range of tools that comes with pytorch\n",
    "- we make the dtye=torch.long because it's int64 rather than the default float32. Since the encoder only has integer, there's no need to waste extra space for decimal precision\n",
    "\n",
    "Why do we encode the input?\n",
    "- Since computers can really only understand numbers, we have to numberfy the inputs into numbers so that they can be interpreted by the computer\n",
    "- We set words/characters to numbers so that the number will the representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up the data into training set and validation sets\n",
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]           # Used for training\n",
    "val_data = data[n:]             # Used to test how good the model is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- When we create a model, we want it to also solve problems outside of its training dataset. If a model is only good at doing what it's trained on, then it can't be generalized, which is useless\n",
    "- That is why we leave 10% of the data for validation purposes, to see how the model performs when it encounters something outside of its training set, or in other words, to see to what extent is the model overfitting\n",
    "- Overfitting is bad, because even if the model can predict the training set to a high degree, it'll not translate well to data that it has never seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given tensor([18]), my target is 47\n",
      "Given tensor([18, 47]), my target is 56\n",
      "Given tensor([18, 47, 56]), my target is 57\n",
      "Given tensor([18, 47, 56, 57]), my target is 58\n",
      "Given tensor([18, 47, 56, 57, 58]), my target is 1\n",
      "Given tensor([18, 47, 56, 57, 58,  1]), my target is 15\n",
      "Given tensor([18, 47, 56, 57, 58,  1, 15]), my target is 47\n",
      "Given tensor([18, 47, 56, 57, 58,  1, 15, 47]), my target is 58\n"
     ]
    }
   ],
   "source": [
    "# Selecting blocks \n",
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+ 1]\n",
    "for t in range(block_size):\n",
    "    print(f\"Given {x[:t+1]}, my target is {y[t]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- We pick a small block size, or context length to train data because loading all the dataset at once is impractical, such as limited memory\n",
    "- We select random chunks of the dataset and then train them. Those chunks have a max size\n",
    "\n",
    "Numbers of training data in a block:\n",
    "- When selecting a chunk/block from the dataset, there's actually mulitple training data packed into. See the above code\n",
    "- In a way, this is a bayesian framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6,  1, 52, 53, 58,  1, 58, 47],\n",
       "         [ 6,  1, 54, 50, 39, 52, 58, 43],\n",
       "         [ 1, 58, 46, 47, 57,  1, 50, 47],\n",
       "         [ 0, 32, 46, 43, 56, 43,  1, 42]]),\n",
       " tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
       "         [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
       "         [58, 46, 47, 57,  1, 50, 47, 60],\n",
       "         [32, 46, 43, 56, 43,  1, 42, 53]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4          # How many independent chunks should we process in parallel\n",
    "block_size = 8          # Maximum context length of per chunk\n",
    "\n",
    "def get_batch(split: list) -> tuple[list[int], list[str]]:\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    # We're just implementing the ideas from above cell\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])                   # x values to predict the next token\n",
    "    y = torch.stack([data[i+1: i + block_size+1] for i in ix])              # y values, the target\n",
    "\n",
    "    return x,y\n",
    " \n",
    "get_batch('train_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborations:\n",
    "\n",
    "`ix = torch.randint(len(data) - block_size, (batch_size,))`\n",
    "- Here we are generating `batch_size` amount of random integers to serve as the starting index for getting chunks, where these integers are in [0, `len(data)-block_size`)\n",
    "- The range is so that we don't go oob when we try to get `block_size` amount of data from a starting index\n",
    "- The random indices will be stored in a 1D tensor, as denoted by `(batch_size,)`\n",
    "- The tuple notation signifys that it's a 1D tensor, and if we have something else like `(2,3)`, then that'll be a 2D tensor with dimensions 2X3, meaning 2 rows, each having length 3\n",
    "- If we were to write `(batch_size)` without the ',', then it'll be a scalar tensor, which doesn't make sense if I want to sample random integers and storing those collections in a container\n",
    "\n",
    "---\n",
    "`torch.stack`\n",
    "- A torch stack is when you stack a bunch tensors of SAME dimension n, and it'll become a new tensor with dimension n+1\n",
    "- For example, if I have `tensor(1)`, `tensor(2)`, `tensor(3)`, all 0D, and I stack them via torch.stack, then the resulting tensor will be a 1D vector tensor that looks like `tensor([1,2,3])`\n",
    "- If I have `tensor([1,2,3])` and `tensor([4,5,6])`, then stack will result in a 2X3 matrix\n",
    "- When it comes to training data, we stack those 1D vectors so that each vectors will be trained simultaneously via the parallel processing nature of GPU\n",
    "\n",
    "ex. Training in parallel\n",
    "\n",
    "|   <------ <1,2,3>         my independent vector1\n",
    "\n",
    "|   <------ <4,5,6>         my independent vector2\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "`x = torch.stack([data[i:i + block_size] for i in ix])` \n",
    "- To be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
